{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5085a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk through the data folder, read the comments and write it to text_data.txt file\n",
    "import os\n",
    "from os import walk\n",
    "\n",
    "current_dir = os.getcwd() # First, get the path of the working directory\n",
    "path1 =current_dir+'\\\\data\\\\negative'\n",
    "path2 =current_dir+'\\\\data\\\\positive'\n",
    "\n",
    "_, _, list1 = next(walk(path1))\n",
    "_, _, list2 = next(walk(path2))\n",
    "\n",
    "filename_with_path=current_dir+'\\\\data\\\\'+'Text_Data.txt'\n",
    "f1= open(filename_with_path,\"w+\")\n",
    "f1.close()\n",
    "\n",
    "for i in range(len(list1)):\n",
    " f1 = open(filename_with_path,\"a+\")\n",
    "\n",
    " data=\"\"\n",
    "    \n",
    " f = open(path1+'\\\\'+list1[i])\n",
    " data = f.read()\n",
    "    \n",
    " f.close()\n",
    "\n",
    " f = open(path2+'\\\\'+list2[i])\n",
    "    \n",
    " data=data+f.read()\n",
    " f.close()\n",
    " f1.write(data)\n",
    " f1.close()\n",
    "### This code creates the dataset \"Text_Data.txt\" under ./data\n",
    "path_to_file = current_dir+'\\\\data\\\\'+'Text_Data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42d7bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file. If the code above executed, next time you just need to start here since tetx_data.txt is created\n",
    "import os\n",
    "from os import walk\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "path_to_file = current_dir+'\\\\data\\\\'+'Text_Data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c078290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file\n",
    "text_data_file = open(path_to_file,\"r+\")\n",
    "text_data = text_data_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da11a1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7786004"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4198c432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plot : two teen couples go to a church party , drink and then drive . \\nthey get into an accident . \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0afd4a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x05\\n\\x12\\x13\\x14\\x16 !\"#$%&\\'()*+,-./0123456789:;=>?@[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of different characters\n",
    "\"\".join(sorted(set(text_data.lower()))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80c4af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the text\n",
    "from tensorflow import keras\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "969ce48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w o r n t']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d8296fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7786004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of distinct characters => max_id = 39 in this case.\n",
    "max_id = len(tokenizer.word_index)\n",
    "\n",
    "# total number of characters\n",
    "dataset_size = tokenizer.document_count \n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1358face",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([18, 10,  5, ..., 23,  0, 24])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# encode the full text so each character is represented by its ID\n",
    "[encoded] = np.array(tokenizer.texts_to_sequences([text_data])) - 1\n",
    "[encoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "083c0978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7786004"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82741a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72411827",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "\n",
    "# target = input shifted 1 character ahead\n",
    "window_length = n_steps + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b789b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for stateless RNN\n",
    "dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "\n",
    "dataset = dataset.map((lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch)))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33f497b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100, 74) (32, 100)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, Y_batch in dataset.take(1):\n",
    "    print(X_batch.shape, Y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f60894",
   "metadata": {},
   "source": [
    "Stateless RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b82cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stateless model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     # no dropout in stateful RNN (https://github.com/ageron/handson-ml2/issues/32)\n",
    "                     # dropout=0.2, recurrent_dropout=0.2,\n",
    "                     ),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     # dropout=0.2, recurrent_dropout=0.2\n",
    "                    ),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "\n",
    "# Compile and fit for 10 epochs.\n",
    "# About training these models, I couldn't train them on jupyter notebook because I didn't figure out how to\n",
    "# enable GPU on Jupyter Notebook. Without GPU it takes too long to train.\n",
    "# I copied the code and trained these models on Google Colab and they worked well\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, steps_per_epoch=train_size // batch_size,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa9daf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the text before making the prediction on it\n",
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)\n",
    "\n",
    "tf.random.categorical([[np.log(0.5), np.log(0.4), np.log(0.1)]], num_samples=40).numpy()\n",
    "\n",
    "# Function to predict the next character using temperature t\n",
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model.predict(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
    "\n",
    "# Function to predict the next n (100 in default) characters using temperature t\n",
    "def complete_text(text, n_chars=100, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f84d9",
   "metadata": {},
   "source": [
    "Stateless RNN predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f005b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions of next 100 characters on first character a\n",
    "print(complete_text(\"a\", temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8ea66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions of next 100 characters on first character s\n",
    "print(complete_text(\"s\", temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bded6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions of next 100 characters on first character t\n",
    "print(complete_text(\"t\", temperature=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb93aea",
   "metadata": {},
   "source": [
    "Statefull RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2259a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for the statefull RNN\n",
    "batch_size = 32\n",
    "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
    "datasets = []\n",
    "for encoded_part in encoded_parts:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
    "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "    datasets.append(dataset)\n",
    "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
    "dataset = dataset.repeat().map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58a7c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statefull model\n",
    "stateFullModel = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                     dropout=0.2, recurrent_dropout=0.2,\n",
    "                     batch_input_shape=[batch_size, None, max_id]),\n",
    "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2ba1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit\n",
    "stateFullModel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "steps_per_epoch = train_size // batch_size // n_steps\n",
    "stateFullModel.fit(dataset, steps_per_epoch=steps_per_epoch, epochs=50,\n",
    "                   callbacks=[ResetStatesCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087055f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a statless copy so the model can predict on batches with different size\n",
    "stateless_copy = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "\n",
    "stateless_copy.build(tf.TensorShape([None, None, max_id]))\n",
    "stateless_copy.set_weights(stateFullModel.get_weights())\n",
    "\n",
    "model = stateless_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74800182",
   "metadata": {},
   "source": [
    "Statefull RNN predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe99ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions of next 100 characters on first character a\n",
    "print(complete_text(\"a\", temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce9ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions of next 100 characters on first character s\n",
    "print(complete_text(\"s\", temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecafae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions of next 100 characters on first character t\n",
    "print(complete_text(\"t\", temperature=0.2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
